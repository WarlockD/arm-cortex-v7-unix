/*
 * memory.hpp
 *
 *  Created on: Apr 27, 2017
 *      Author: Paul
 */

#ifndef OS_MEMORY_HPP_
#define OS_MEMORY_HPP_



//#include <sys\queue.h>

#include "types.hpp"
#include "slist.hpp"


namespace os {
	class as_t;
	/*
	 * Each address space is associated with one or more thread.
	 * AS represented as linked list of fpages, mappings are the same.
	 */
	enum class map_action_t{ MAP, GRANT, UNMAP } ;
	enum class MPT {
		KERNEL_TEXT,
		KERNEL_DATA,
		USER_TEXT,
		USER_DATA,
		AVAILABLE,
		DEVICES,
		UNKNOWN = -1
	} ;
	enum class mpu_state_t {
		DISABLED,
		ENABLED
	} ;

	enum class MP  {
		ZER0 = 0,
		/* Kernel permissions flags */
		KR	=	0x0001,
		KW	=	0x0002,
		KX	=	0x0004,

		/* Userspace permissions flags */
		UR	=	0x0010,
		UW	=	0x0020,
		UX	=	0x0040,

		/* Fpage type */
		NO_FPAGE	=0x0000,		/*! Not mappable */
		SRAM		=0x0100,		/*! Fpage in SRAM: granularity 1 << */
		AHB_RAM		=0x0200,		/*! Fpage in AHB SRAM: granularity 64 words, bit bang mappings */
		DEVICES		=0x0400,		/*! Fpage in AHB/APB0/AHB0: granularity 16 kB */
		MEMPOOL		=0x0800,		/*! Entire mempool is mapped  */

		MAP_ALWAYS 	=0x1000,
		FPAGE_MASK 	=0x0F00,

	};
	constexpr static inline  MP operator|(MP l, MP r) {
		using U = typename std::underlying_type<MP>::type;
		return static_cast<MP>(static_cast<U>(l) | static_cast<U>(l));
	}
	constexpr static inline  MP operator&(MP l, MP r) {
		using U = typename std::underlying_type<MP>::type;
		return static_cast<MP>(static_cast<U>(l) & static_cast<U>(l));
	}
	constexpr static inline  MP operator~(MP l) {
		using U = typename std::underlying_type<MP>::type;
		return static_cast<MP>(~static_cast<U>(l));
	}

	/* Map memory from mempool always (for example text is mapped always because
	 * without it thread couldn't run)
	 * other fpages mapped on request because we limited in MPU resources)
	 */
	constexpr static inline uint8_t MP_USER_PERM(MP flags) {
		using U = typename std::underlying_type<MP>::type;
		return static_cast<uint8_t>((static_cast<U>(flags)& 0xF0) >> 4);
	}

	/* Mapping value for NO FPAGE region */
	constexpr static memptr_t INVALID_FPAGE_REGION =0xffffffff;
	/**
	 * Flexible page (fpage_t)
	 *
	 * as_next - next in address space chain
	 * map_next - next in mappings chain (cycle list)
	 *
	 * base - base address of fpage
	 * shift - size of fpage == 1 << shift
	 * rwx - access bits
	 * mpid - id of memory pool
	 * flags - flags
	 */
	struct fpage_t {
		static constexpr uint32_t CONFIG_MAX_FPAGES = 20;
		static constexpr uint32_t FPAGE_ALWAYS    = 0x1;     /*! Fpage is always mapped in MPU */
		static constexpr uint32_t FPAGE_CLONE     = 0x2;     /*! Fpage is mapped from other AS */
		static constexpr uint32_t FPAGE_MAPPED    = 0x4;     /*! Fpage is mapped with MAP (  unavailable in original AS) */
		sys::slist_entry<fpage_t> as;
		sys::slist_entry<fpage_t> map;
		sys::slist_entry<fpage_t> mpu;

		union {
			struct {
				uint32_t base;
				uint32_t mpid : 6;
				uint32_t flags : 6;
				uint32_t shift : 16;
				uint32_t rwx : 4;
			} fpage;
			uint32_t raw[2];
		};
#if 0
		template<typename FT, typename FN>
		void remove_fpage_from_list(as_t* as, fpage_t* fpage, FT _first, FN _next) {
			auto& first = std::mem_fn(_first);
			auto& next = std::mem_fn(_next);
			fpage_t *fpprev = first(as);
			int end;
			if(fpage != fpprev){
				first(as) = next(fpprev);
			} else {
				while(!end && next(fpprev) != fpage) {
					if(next(fpprev) == nullptr) end = 1;
					fpprev = next(fpprev);
				}
				next(fpprev) = next(fpage);
			}
		}
#endif
		inline uint32_t base() const { return fpage.base; }
		inline uint32_t size() const { return 1<<fpage.shift; }
		inline uint32_t begin() const { return fpage.base; }
		inline uint32_t end() const { return base() + size(); }
		bool addr_in(memptr_t addr, int incl_end) const {
			return ((addr >= base() && addr <  end()) || (incl_end && addr ==  end()));
		}
		static void fpages_init(void);
		static  fpage_t *split_fpage(as_t *as, fpage_t *fpage, memptr_t split, int rl);

		static int assign_fpages(as_t *as, memptr_t base, size_t size);
		static int assign_fpages_ext(int mpid, as_t *as, memptr_t base, size_t size,
		                      fpage_t **pfirst, fpage_t **plast);

		static int map_fpage(as_t *src, as_t *dst, fpage_t *fpage, map_action_t action);
		static int unmap_fpage(as_t *as, fpage_t *fpage);
		static void destroy_fpage(fpage_t *fpage);
	#ifdef CONFIG_KDB
		int used;
	#endif /* CONFIG_KDB */
		static void* operator new(size_t size);
		static void operator delete(void* ptr);
		inline bool operator<(const fpage_t& f) const { return fpage.base < f.fpage.base; }
		fpage_t(memptr_t base, size_t shift, int mpid);
	private:
		static fpage_t *create_fpage(memptr_t base, size_t shift, int mpid);
				static void create_fpage_chain(memptr_t base, size_t size, int mpid,
				                               fpage_t **pfirst, fpage_t **plast);
	};

	struct as_t{
		uint32_t as_spaceid;	/*! Space Identifier */

		sys::slist_head<fpage_t,&fpage_t::as> as_head;
		sys::slist_head<fpage_t,&fpage_t::map> map_head;
		sys::slist_head<fpage_t,&fpage_t::mpu> mpu_head;

		//fpage_t *first;	/*! head of fpage list */

	//	fpage_t *mpu_first;	/*! head of MPU fpage list */
		//fpage_t *mpu_stack_first;	/*! head of MPU stack fpage list */
		uint32_t shared;	/*! shared user number */
		static int map_area(as_t& src, as_t& dst, memptr_t base, size_t size, map_action_t action, bool is_priviliged);
		static as_t *as_create(uint32_t as_spaceid);
		static void as_destroy(as_t *as);
		static void as_setup_mpu(as_t& as, memptr_t sp, memptr_t pc, memptr_t stack_base, size_t stack_size);
		void map_user();
		void map_ktext();
		static void mpu_enable(mpu_state_t i);
		static void mpu_setup_region(int n, fpage_t *fp);
		int mpu_select_lru(uint32_t addr);
		static constexpr size_t CONFIG_MAX_ADRESS_SPACES = 54;
		static void* operator new(size_t size);
		static void operator delete(void* ptr);
	private:
		void insert_fpage_chain_to_as(fpage_t *first, fpage_t *last);
		void insert_fpage_to_as(fpage_t *fpage);
		void remove_fpage_from_as(fpage_t *fp);

		fpage_t *split_fpage(as_t *as, fpage_t *fpage, memptr_t split, int rl);
	} ;
	/**
	 * Memory pool represents area of physical address space
	 * We set flags to it (kernel & user permissions),
	 * and rules for fpage creation
	 */
#if 0
	template<typename T>
	constexpr static inline memptr_t to_memptr(T v) {
		return reinterpret_cast<memptr_t>(reinterpret_cast<void*>(v));
	} ;
#endif


	struct mempool_t {
		const char *name;
		const memptr_t start;
		const memptr_t end;
		const MP flags;
		const MPT tag;
		template<typename START_T, typename END_T>
		constexpr mempool_t(const char* name, START_T start, END_T end, MP flags, MPT tag)
		: name(name),
		  start(reinterpret_cast<memptr_t>(reinterpret_cast<void*>(start))),
		  end(reinterpret_cast<memptr_t>(reinterpret_cast<void*>(end))),
		  flags(flags),
		  tag(tag) {}

	} ;


}; /* namespace os */
#endif /* OS_MEMORY_HPP_ */
