/*
 * memory.hpp
 *
 *  Created on: Apr 27, 2017
 *      Author: Paul
 */

#ifndef OS_MEMORY_HPP_
#define OS_MEMORY_HPP_



//#include <sys\queue.h>

#include "types.hpp"
#include "slist.hpp"


namespace os {

	namespace mpu {
		 enum class Attributes : uint32_t {
			 // disable excuting
			 DisableExec = (1<<28U),

			 //Access_PNO_UNO = 0x0,  // 000 No access No access All accesses generate a permission fault
			 Access_PRW_UNO = 0x1<<24, 	// 001 RW No access Access from a privileged software only
			 Access_PRW_URO = 0x2<<24, 	//010 RW RO Written by an unprivileged software generate a permission fault
			 Access_PRW_URW = 0x3<<24, 	//011 RW RW Full access
	//????? = 0x4// 100 Unpredictable Unpredictable Reserved
			 Access_PRO_UNO = 0x5<<24, 	// 101 RO No access Read by a privileged software only
			 Access_PRO_URO2 = 0x6<<24, 	//RO RO Read only, by privileged or unprivileged software
			 Access_PRO_URO3 = 0x7<<24, 	//RO RO Read only, by privileged or unprivileged software

			 // Caching properties
			 // TEX C B S Memory Type Description Shareable
			 // Cache_StronglyOrdered = 0x00,
#define IGNORE 0
#define CACHE_PROPERTIES(TEX, C, B, S) ((TEX&7)<<19U) | (C<<17U) | (B<<16) | (S<<18)
			 Cache_DeviceShared = CACHE_PROPERTIES(0,0,1, IGNORE), // S dosnt matter
			 Cache_NormalWriteThoughNoWriteAllocate = ((0&7)<<19U) | (1<<17U) | (0<<16) | (0<<18),
			 Cache_NormalWriteThoughNoWriteAllocateShared = ((0&7)<<19U) | (1<<17U) | (0<<16) | (1<<18),

			 000 0 1 Device Shared Device Yes
			 000 1 0 Normal Write through, no write allocate S bit
			 000 1 1 Normal Write-back, no write allocate S bit
			 001 0 0 Normal Non-cacheable S bit
			 001 0 1 Reserved Reserved Reserved
			 001 1 0 Undefined Undefined Undefined
			 001 1 1 Normal Write-back, write and read allocate S bit
			 010 0 0 Device Non-shareable device No
			 010 0 1 Reserved Reserved Reserved
		 };
			Enable = 0x01,
			Disable = 0x00
		};
		 enum class InstructionAccess : uint8_t {
			Enable = 0x00,
			Disable = 0x01
		};
		 enum class Access : uint8_t {
			 	 NoSharable = 0x00,
				Sharable = 0x01
			};
		 enum class RegionSize {
			 21:19 TEX Type Extension field
			 18 S Shareable
			 17 C Cacheable
			 16 B Bufferable
		 };
		 MPU->RNR = MPU_Init->Number;

		  if ((MPU_Init->Enable) != RESET)
		  {
		    /* Check the parameters */
		    assert_param(IS_MPU_INSTRUCTION_ACCESS(MPU_Init->DisableExec));
		    assert_param(IS_MPU_REGION_PERMISSION_ATTRIBUTE(MPU_Init->AccessPermission));
		    assert_param(IS_MPU_TEX_LEVEL(MPU_Init->TypeExtField));
		    assert_param(IS_MPU_ACCESS_SHAREABLE(MPU_Init->IsShareable));
		    assert_param(IS_MPU_ACCESS_CACHEABLE(MPU_Init->IsCacheable));
		    assert_param(IS_MPU_ACCESS_BUFFERABLE(MPU_Init->IsBufferable));
		    assert_param(IS_MPU_SUB_REGION_DISABLE(MPU_Init->SubRegionDisable));
		    assert_param(IS_MPU_REGION_SIZE(MPU_Init->Size));

		    MPU->RBAR = MPU_Init->BaseAddress;
		    MPU->RASR = ((uint32_t)MPU_Init->DisableExec             << MPU_RASR_XN_Pos)   |
		                ((uint32_t)MPU_Init->AccessPermission        << MPU_RASR_AP_Pos)   |
		                ((uint32_t)MPU_Init->TypeExtField            << MPU_RASR_TEX_Pos)  |
		                ((uint32_t)MPU_Init->IsShareable             << MPU_RASR_S_Pos)    |
		                ((uint32_t)MPU_Init->IsCacheable             << MPU_RASR_C_Pos)    |
		                ((uint32_t)MPU_Init->IsBufferable            << MPU_RASR_B_Pos)    |
		                ((uint32_t)MPU_Init->SubRegionDisable        << MPU_RASR_SRD_Pos)  |
		                ((uint32_t)MPU_Init->Size                    << MPU_RASR_SIZE_Pos) |
		                ((uint32_t)MPU_Init->Enable                  << MPU_RASR_ENABLE_Pos);
	};
	enum class AP {

	};
	28 XN Execute never
	26:24 AP Data Access Permission field (RO, RW or No access)
	21:19 TEX Type Extension field
	18 S Shareable
	17 C Cacheable
	16 B Bufferable
	15:8 SRD Subregion disable. For each subregion 1=disabled, 0=enabled.
	5:1 SIZE Specifies the size of the MPU protection region.



	/*
	 * Each address space is associated with one or more thread.
	 * AS represented as linked list of fpages, mappings are the same.
	 */
	enum class map_action_t{ MAP, GRANT, UNMAP } ;
	enum class MPT {
		KERNEL_TEXT,
		KERNEL_DATA,
		USER_TEXT,
		USER_DATA,
		AVAILABLE,
		DEVICES,
		UNKNOWN = -1
	} ;
	enum class mpu_state_t {
		DISABLED,
		ENABLED
	} ;

	enum class MP  {
		ZERO = 0,
		/* Kernel permissions flags */
		KR	=	0x0001,
		KW	=	0x0002,
		KX	=	0x0004,

		/* Userspace permissions flags */
		UR	=	0x0010,
		UW	=	0x0020,
		UX	=	0x0040,

		/* Fpage type */
		NO_FPAGE	=0x0000,		/*! Not mappable */
		SRAM		=0x0100,		/*! Fpage in SRAM: granularity 1 << */
		AHB_RAM		=0x0200,		/*! Fpage in AHB SRAM: granularity 64 words, bit bang mappings */
		DEVICES		=0x0400,		/*! Fpage in AHB/APB0/AHB0: granularity 16 kB */
		MEMPOOL		=0x0800,		/*! Entire mempool is mapped  */

		MAP_ALWAYS 	=0x1000,
		FPAGE_MASK 	=0x0F00,

	};
	constexpr static inline  MP operator|(MP l, MP r) {
		using U = typename std::underlying_type<MP>::type;
		return static_cast<MP>(static_cast<U>(l) | static_cast<U>(l));
	}
	constexpr static inline  MP operator&(MP l, MP r) {
		using U = typename std::underlying_type<MP>::type;
		return static_cast<MP>(static_cast<U>(l) & static_cast<U>(l));
	}
	constexpr static inline  MP operator~(MP l) {
		using U = typename std::underlying_type<MP>::type;
		return static_cast<MP>(~static_cast<U>(l));
	}

	/* Map memory from mempool always (for example text is mapped always because
	 * without it thread couldn't run)
	 * other fpages mapped on request because we limited in MPU resources)
	 */
	constexpr static inline uint8_t MP_USER_PERM(MP flags) {
		using U = typename std::underlying_type<MP>::type;
		return static_cast<uint8_t>((static_cast<U>(flags)& 0xF0) >> 4);
	}

	/* Mapping value for NO FPAGE region */
	constexpr static memptr_t INVALID_FPAGE_REGION =0xffffffff;
	/**
	 * Flexible page (fpage_t)
	 *
	 * as_next - next in address space chain
	 * map_next - next in mappings chain (cycle list)
	 *
	 * base - base address of fpage
	 * shift - size of fpage == 1 << shift
	 * rwx - access bits
	 * mpid - id of memory pool
	 * flags - flags
	 */
	struct fpage_t {
		static constexpr uint32_t CONFIG_MAX_FPAGES = 20;
		static constexpr uint32_t FPAGE_ALWAYS    = 0x1;     /*! Fpage is always mapped in MPU */
		static constexpr uint32_t FPAGE_CLONE     = 0x2;     /*! Fpage is mapped from other AS */
		static constexpr uint32_t FPAGE_MAPPED    = 0x4;     /*! Fpage is mapped with MAP (  unavailable in original AS) */
		sys::slist_entry<fpage_t> as;
		sys::slist_entry<fpage_t> map;
		sys::slist_entry<fpage_t> mpu;

		union {
			struct {
				uint32_t base;
				uint32_t mpid : 6;
				uint32_t flags : 6;
				uint32_t shift : 16;
				uint32_t rwx : 4;
			} fpage;
			uint32_t raw[2];
		};
#if 0
		template<typename FT, typename FN>
		void remove_fpage_from_list(as_t* as, fpage_t* fpage, FT _first, FN _next) {
			auto& first = std::mem_fn(_first);
			auto& next = std::mem_fn(_next);
			fpage_t *fpprev = first(as);
			int end;
			if(fpage != fpprev){
				first(as) = next(fpprev);
			} else {
				while(!end && next(fpprev) != fpage) {
					if(next(fpprev) == nullptr) end = 1;
					fpprev = next(fpprev);
				}
				next(fpprev) = next(fpage);
			}
		}
#endif
		inline uint32_t base() const { return fpage.base; }
		inline uint32_t size() const { return 1<<fpage.shift; }
		inline uint32_t begin() const { return fpage.base; }
		inline uint32_t end() const { return base() + size(); }
		inline uint32_t flags() const { return fpage.flags; }
		bool addr_in(memptr_t addr, int incl_end) const {
			return ((addr >= base() && addr <  end()) || (incl_end && addr ==  end()));
		}
		static void fpages_init(void);
		static  fpage_t *split_fpage(as_t *as, fpage_t *fpage, memptr_t split, int rl);

		static int assign_fpages(as_t *as, memptr_t base, size_t size);
		static int assign_fpages_ext(int mpid, as_t *as, memptr_t base, size_t size,
		                      fpage_t **pfirst, fpage_t **plast);

		static int map_fpage(as_t *src, as_t *dst, fpage_t *fpage, map_action_t action);
		static int unmap_fpage(as_t *as, fpage_t *fpage);
		static void destroy_fpage(fpage_t *fpage);
	#ifdef CONFIG_KDB
		int used;
	#endif /* CONFIG_KDB */
		static void* operator new(std::size_t sz);
		static void operator delete(void* ptr);
		inline bool operator<(const fpage_t& f) const { return fpage.base < f.fpage.base; }
		fpage_t(memptr_t base, size_t shift, int mpid);
	private:
		static fpage_t *create_fpage(memptr_t base, size_t shift, int mpid);
				static void create_fpage_chain(memptr_t base, size_t size, int mpid,
				                               fpage_t **pfirst, fpage_t **plast);
	};

	struct as_t{
		uint32_t as_spaceid;	/*! Space Identifier */

		sys::slist_head<fpage_t,&fpage_t::as> as_head;
		sys::slist_head<fpage_t,&fpage_t::map> map_head;
		sys::slist_head<fpage_t,&fpage_t::mpu> mpu_head;

		//fpage_t *first;	/*! head of fpage list */

		//fpage_t *mpu_first;	/*! head of MPU fpage list */
		//fpage_t *mpu_stack_first;	/*! head of MPU stack fpage list */
		uint32_t shared;	/*! shared user number */
		static int map_area(as_t& src, as_t& dst, memptr_t base, size_t size, map_action_t action, bool is_priviliged);
		static as_t *as_create(uint32_t as_spaceid);
		static void as_destroy(as_t *as);
		static void as_setup_mpu(as_t& as, memptr_t sp, memptr_t pc, memptr_t stack_base, size_t stack_size);
		void map_user();
		void map_ktext();
		static void mpu_enable(mpu_state_t i);
		static void mpu_setup_region(int n, fpage_t *fp);
		int mpu_select_lru(uint32_t addr);
		static constexpr size_t CONFIG_MAX_ADRESS_SPACES = 54;
		static void* operator new(std::size_t sz);
		static void operator delete(void* ptr);
		void setup_mpu(memptr_t sp, memptr_t pc, memptr_t stack_base, size_t stack_size);
	private:
		void insert_fpage_chain_to_as(fpage_t *first, fpage_t *last);
		void insert_fpage_to_as(fpage_t *fpage);
		void remove_fpage_from_as(fpage_t *fp);

		fpage_t *split_fpage(as_t *as, fpage_t *fpage, memptr_t split, int rl);
	} ;
	/**
	 * Memory pool represents area of physical address space
	 * We set flags to it (kernel & user permissions),
	 * and rules for fpage creation
	 */
#if 0
	template<typename T>
	constexpr static inline memptr_t to_memptr(T v) {
		return reinterpret_cast<memptr_t>(reinterpret_cast<void*>(v));
	} ;
#endif


	struct mempool_t {
		const char *name;
		const memptr_t start;
		const memptr_t end;
		const MP flags;
		const MPT tag;
		template<typename START_T, typename END_T>
		constexpr mempool_t(const char* name, START_T start, END_T end, MP flags, MPT tag)
		: name(name),
		  start(reinterpret_cast<memptr_t>(reinterpret_cast<void*>(start))),
		  end(reinterpret_cast<memptr_t>(reinterpret_cast<void*>(end))),
		  flags(flags),
		  tag(tag) {}

	} ;


}; /* namespace os */
#endif /* OS_MEMORY_HPP_ */
