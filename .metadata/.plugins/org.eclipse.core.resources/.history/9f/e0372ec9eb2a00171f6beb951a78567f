#ifndef _ATOMIC_H_
#define _ATOMIC_H_

//#include "conf.h"
#include <cstdint>
#include <cstddef>
#include <functional>
#include <type_traits>


namespace ASM {
	template<typename T, size_t size> struct EXCLUSIVE {};
	template<typename T> struct EXCLUSIVE<T,1> {
		static constexpr bool type_is_signed = std::is_unsigned<T>::value;
		static constexpr bool type_size = 1;
		using type = T;

		__attribute__((always_inline)) static inline uint32_t STREX(T value, volatile T *addr){
			uint32_t result;
			   __asm volatile ("strexb %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
			   return(result);
		}
		__attribute__((always_inline)) static inline T LDREX(volatile T *addr)
		{
		    uint32_t result;
		    __asm volatile ("ldrexb %0, %1" : "=r" (result) : "Q" (*addr) );
		   return static_cast<T>(result);
		}
		__attribute__((always_inline)) static inline void CLREX(void)
		{
		  __asm volatile ("clrex" ::: "memory");
		}
		__attribute__((always_inline)) static inline T XCHG(T nvalue, volatile T *ptr) {
			uint32_t tmp;
			uint32_t ret;
			__builtin_prefetch((const void*)ptr,1);
			asm volatile(
			"1:	ldrexb	%0, [%3]\n"
			"	strexb	%1, %2, [%3]\n"
#ifdef DISABLE_THUMB2
			"	teq	%1, #0\n"
			"	bne	1b"
#else
			"	cbz	%1, 1b\n"
#endif
				: "=&r" (ret), "=&r" (tmp)
				: "r" (nvalue), "r" (ptr)
				: "memory", "cc");
			return static_cast<T>(ret);
		}
		__attribute__((always_inline)) static inline T ADD(T value, T *ptr) {
				T tmp;
				int result;
				__asm__ __volatile__(
						"1:	ldrexb	%0, [%2]\n"
						"	add	%0, %0, %3\n"
						"	strexb	%1, %0, [%2]\n"
	#ifdef DISABLE_THUMB2
				"	teq	%1, #0\n"
				"	bne	1b"
	#else
				"	cbz	%1, 1b\n"
	#endif
				: "=&r" (result), "=&r" (tmp)
				: "r" (ptr), "Ir" (value)
				: "cc");
				return result;
			}
			__attribute__((always_inline)) static inline T SUB(T value, T *ptr) {
				T tmp;
				int result;
				__asm__ __volatile__(
						"1:	ldrexb	%0, [%2]\n"
						"	sub	%0, %0, %3\n"
						"	strexb	%1, %0, [%2]\n"
	#ifdef DISABLE_THUMB2
				"	teq	%1, #0\n"
				"	bne	1b"
	#else
				"	cbz	%1, 1b\n"
	#endif
				: "=&r" (result), "=&r" (tmp)
				: "r" (ptr), "Ir" (value)
				: "cc");
				return result;
			}

	};

	template<typename T> struct EXCLUSIVE<T,2> {
		static constexpr bool type_is_signed = std::is_unsigned<T>::value;
		static constexpr bool type_size = 2;
		using type = T;

		__attribute__((always_inline)) static inline uint32_t STREX(T value, volatile T *addr){
			uint32_t result;
			   __asm volatile ("strexh %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
			   return(result);
		}
		__attribute__((always_inline)) static inline T LDREX(volatile T *addr)
		{
		    uint32_t result;
		    __asm volatile ("ldrexh %0, %1" : "=r" (result) : "Q" (*addr) );
		   return static_cast<T>(result);
		}
		__attribute__((always_inline)) static inline void CLREX(void)
		{
		  __asm volatile ("clrex" ::: "memory");
		}
		__attribute__((always_inline)) static inline T XCHG(T nvalue, volatile T *ptr) {
			uint32_t tmp;
			uint32_t ret;
			__builtin_prefetch((const void*)ptr,1);
			asm volatile(
			"1:	ldrexh	%0, [%3]\n"
			"	strexh	%1, %2, [%3]\n"
#ifdef DISABLE_THUMB2
			"	teq	%1, #0\n"
			"	bne	1b"
#else
			"	cbz	%1, 1b\n"
#endif
				: "=&r" (ret), "=&r" (tmp)
				: "r" (nvalue), "r" (ptr)
				: "memory", "cc");
			return static_cast<T>(ret);
		}
		__attribute__((always_inline)) static inline T ADD(T value, T *ptr) {
			T tmp;
			int result;
			__asm__ __volatile__(
					"1:	ldrexh	%0, [%2]\n"
					"	add	%0, %0, %3\n"
					"	strexh	%1, %0, [%2]\n"
#ifdef DISABLE_THUMB2
			"	teq	%1, #0\n"
			"	bne	1b"
#else
			"	cbz	%1, 1b\n"
#endif
			: "=&r" (result), "=&r" (tmp)
			: "r" (ptr), "Ir" (value)
			: "cc");
			return result;
		}
		__attribute__((always_inline)) static inline T SUB(T value, T *ptr) {
			T tmp;
			int result;
			__asm__ __volatile__(
					"1:	ldrexh	%0, [%2]\n"
					"	sub	%0, %0, %3\n"
					"	strexh	%1, %0, [%2]\n"
#ifdef DISABLE_THUMB2
			"	teq	%1, #0\n"
			"	bne	1b"
#else
			"	cbz	%1, 1b\n"
#endif
			: "=&r" (result), "=&r" (tmp)
			: "r" (ptr), "Ir" (value)
			: "cc");
			return result;
		}
	};
	template<typename T> struct EXCLUSIVE<T,4> {
		static constexpr bool type_is_signed = std::is_unsigned<T>::value;
		static constexpr bool type_size = 2;
		using type = T;

		__attribute__((always_inline)) static inline uint32_t STREX(T value, volatile T *addr){
			uint32_t result;
			   __asm volatile ("strex %0, %2, %1" : "=&r" (result), "=Q" (*addr) : "r" (value) );
			   return(result);
		}
		__attribute__((always_inline)) static inline T LDREX(volatile T *addr)
		{
		    uint32_t result;
		    __asm volatile ("ldrex %0, %1" : "=r" (result) : "Q" (*addr) );
		   return static_cast<T>(result);
		}
		__attribute__((always_inline)) static inline void CLREX(void)
		{
		  __asm volatile ("clrex" ::: "memory");
		}
		__attribute__((always_inline)) static inline T XCHG(T nvalue, volatile T *ptr) {
			uint32_t tmp;
			uint32_t ret;
			__builtin_prefetch((const void*)ptr,1);
			asm volatile(
			"1:	ldrex	%0, [%3]\n"
			"	strex	%1, %2, [%3]\n"
#ifdef DISABLE_THUMB2
			"	teq	%1, #0\n"
			"	bne	1b"
#else
			"	cbz	%1, 1b\n"
#endif
				: "=&r" (ret), "=&r" (tmp)
				: "r" (nvalue), "r" (ptr)
				: "memory", "cc");
			return static_cast<T>(ret);
		}
		__attribute__((always_inline)) static inline T ADD(T value, T *ptr) {
			T tmp;
			int result;
			__asm__ __volatile__(
					"1:	ldrex	%0, [%2]\n"
					"	add	%0, %0, %3\n"
					"	strex	%1, %0, [%2]\n"
#ifdef DISABLE_THUMB2
			"	teq	%1, #0\n"
			"	bne	1b"
#else
			"	cbz	%1, 1b\n"
#endif
			: "=&r" (result), "=&r" (tmp)
			: "r" (ptr), "Ir" (value)
			: "cc");
			return result;
		}
		__attribute__((always_inline)) static inline T SUB(T value, T *ptr) {
			T tmp;
			int result;
			__asm__ __volatile__(
					"1:	ldrex	%0, [%2]\n"
					"	sub	%0, %0, %3\n"
					"	strex	%1, %0, [%2]\n"
#ifdef DISABLE_THUMB2
			"	teq	%1, #0\n"
			"	bne	1b"
#else
			"	cbz	%1, 1b\n"
#endif
			: "=&r" (result), "=&r" (tmp)
			: "r" (ptr), "Ir" (value)
			: "cc");
			return result;
		}
	};
#define CREATE_MSR_MRS_STRUCT(REGNAME) 											\
	struct REGNAME { 															\
		__attribute__( ( always_inline ) ) static inline uint32_t get() { 		\
		  	  uint32_t result;													\
		  	  __asm volatile ("MRS %0," #REGNAME : "=r" (result) );				\
		  	  return(result);													\
		}																		\
		__attribute__( ( always_inline ) ) static inline void set(uint32_t v) { \
			__asm volatile ("MSR " #REGNAME ", %0" : : "r" (v) : "memory");		\
		}																		\
	};
	CREATE_MSR_MRS_STRUCT(CONTROL);
	CREATE_MSR_MRS_STRUCT(IPSR);
	CREATE_MSR_MRS_STRUCT(APSR);
	CREATE_MSR_MRS_STRUCT(PSP);
	CREATE_MSR_MRS_STRUCT(MSP);
	CREATE_MSR_MRS_STRUCT(PRIMASK);
	CREATE_MSR_MRS_STRUCT(FAULTMASK);
	CREATE_MSR_MRS_STRUCT(BASEPRI);
	CREATE_MSR_MRS_STRUCT(BASEPRI_MAX);


	struct FPSCR {
		__attribute__( ( always_inline ) ) static inline uint32_t get() {
		  	  uint32_t result;
				__asm volatile ("");
				__asm volatile ("VMRS %0, fpscr" : "=r" (result) );
				__asm volatile ("");
		  	  return(result);
		}
		__attribute__( ( always_inline ) ) static inline void set(uint32_t v) {
			__asm volatile ("");
			__asm volatile ("VMSR fpscr, %0" : : "r" (fpscr) : "vfpcc");
			__asm volatile ("");
		}
	};
	template<typename T>
	struct REG {
		__attribute__( ( always_inline ) ) static inline uint32_t get() { return T::get(); }
		__attribute__( ( always_inline ) ) static inline void set(uint32_t v) { T::set(v); }
		__attribute__( ( always_inline ) ) inline REG& operator=(uint32_t v) const { T::set(v); return *this; }
		__attribute__( ( always_inline ) ) inline operator uint32_t() const { return T::get(); }
	};
}
__attribute__( ( always_inline ) ) static inline void irq_enable() { __asm volatile ("cpsie i" : : : "memory"); }
__attribute__( ( always_inline ) ) static inline void irq_disable() { __asm volatile ("cpsid i" : : : "memory"); }
__attribute__( ( always_inline ) ) static inline void fault_irq_enable() { __asm volatile ("cpsie f" : : : "memory"); }
__attribute__( ( always_inline ) ) static inline void fault_irq_disable() { __asm volatile ("cpsid f" : : : "memory"); }
using CONTROL = ASM::REG<ASM::CONTROL>;

template<typename T, typename EX = ASM::EXCLUSIVE<T,sizeof(T)>>
static inline bool atomic_test_and_set(T *ptr)
{
	return EX::XCHG(1,ptr) == 1;
}
template<typename T, typename U, typename EX = ASM::EXCLUSIVE<T,sizeof(T)>>
static inline T atomic_xchg(volatile T *ptr, U v) {
	return EX::XCHG(static_cast<T>(v),ptr);
}
template<typename T, typename U, typename EX = ASM::EXCLUSIVE<T,sizeof(T)>>
static inline T xchg(volatile T *ptr, U v) {
	return EX::XCHG(static_cast<T>(v),ptr);
}
template<typename T, typename U, typename EX = ASM::EXCLUSIVE<T,sizeof(T)>>
static inline T atomic_add(volatile T *ptr, U v) {
	return EX::ADD(static_cast<T>(v),ptr);
}
template<typename T, typename U, typename EX = ASM::EXCLUSIVE<T,sizeof(T)>>
static inline T atomic_sub(volatile T *ptr, U v) {
	return EX::SUB(static_cast<T>(v),ptr);
}


#endif
